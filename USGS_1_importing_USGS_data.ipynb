{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of this file is the great database by USGS found at https://emp.lbl.gov/publications/us-wind-turbine-database-files, officially cited as:\n",
    "Hoen, B.D., Diffendorfer, J.E., Rand, J.T., Kramer, L.A., Garrity, C.P., and Hunt, H.E., 2018, United States Wind Turbine Database (ver. 3.2, October 14, 2020): U.S. Geological Survey, American Wind Energy Association, and Lawrence Berkeley National Laboratory data release, https://doi.org/10.5066/F7TX3DN0.\n",
    "\n",
    "In an operational assessment, it is critical understand the location of neighboring wind plants in relation to wind plant under study as they be a source of external waking. Waking is nothing more than unexpected energy extraction, resultingin lower wind speeds than modeled, and lost energy to the wind plant under study. The external wakes can be very low to zero for wind plants 5km away or further, but it is not unheard of in areas of extreme buildout - some regions of Texas, Tehachapi Pass in CA as examples - to see external wakes equivalent to several percent of annual energy when the neighbor wind plant is immediately upwind in the prevailing wind direction.\n",
    "\n",
    "In this workbook, we'll import the data and normalize it - splitting facility info and turbine info to align with our facility/asset model. As you'll see in other workbooks we use the more generic descriptions so we can use the same tables for both wind and solar assets as so many energy companies are mixing the two technologies.\n",
    "\n",
    "This notebook will import the raw CSV from the October 2020 update, import it into SQL, and then we will step through the steps necessary to normalize the flat file data into the associated relational database format and finally we'll convert numeric lat/lon to allow proper geospatial representation.\n",
    "\n",
    "As we do in other modules, we'll create a connection to our postgres database, import the raw data into a sandbox schema to make sure we're not messing with production tables, and then normalize the flat file data. A quick stufy of the data shows there are 3 different datasets that have been combined that can be aligned nicely with our representation implemented in notebook OADB_JNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sandbox if it doesn't exist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import raw data into sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create facility asset and asset type summaries from flat file in sand box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load 3 tables into baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
