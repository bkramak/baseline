{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code module picks up where the 00 module left off.  Data has been downloaded and the raw_data.csv file has been renamed to raw_data_lhbvlh_2014_2015.csv.\n",
    "\n",
    "We can check by looking at the directory Output/raw_data subdirectory. If you ran the code in 00 module, the file will be named raw_data.csv. the file posted to gitub and included in the example utility in the container is named raw_data_lhbvlh_2014_2015.csv.  First we'll load required packages and then check the raw_data directory to make sure the file we want is there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bk/baseline/M2_JNB/data\n",
      "total 12988\n",
      "-rw-rw-r-- 1 bk bk    88967 Oct 26 17:52 raw_data.csv\n",
      "drwxrwxr-x 2 bk bk     4096 Oct 26 17:52 .\n",
      "drwxrwxr-x 5 bk bk     4096 Oct 26 17:52 ..\n",
      "-rw-rw-r-- 1 bk bk 13199167 Oct 24 16:10 raw_data_lhbvlh_2014_2015.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pdsqlio\n",
    "import functions\n",
    "import re\n",
    "\n",
    "try:\n",
    "    os.chdir('M2_JNB/data')\n",
    "except:\n",
    "    print('no such directory')\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "! ls -lta # bash shell directory command\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data to import, so next we will connect to the database and do some setup work. We begin by building a connection to the postgres database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter dbname:  bk\n",
      "enter user:  bk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter password: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL 12.4 (Ubuntu 12.4-0ubuntu0.20.04.1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 9.3.0-10ubuntu2) 9.3.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "conn = functions.db_login_and_conn()\n",
    "\n",
    "cur=conn.cursor()\n",
    "cur.execute('select version()')\n",
    "print(cur.fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[('pg_toast',), ('pg_temp_1',), ('pg_toast_temp_1',), ('pg_catalog',), ('public',), ('information_schema',), ('sandbox',)]\n"
     ]
    }
   ],
   "source": [
    "str_sql = \"SELECT exists(select schema_name FROM information_schema.schemata WHERE schema_name = 'sandbox');\"\n",
    "cur.execute(str_sql)\n",
    "conn.commit()\n",
    "schema_exists =cur.fetchone()[0]\n",
    "print(schema_exists)\n",
    "if schema_exists==False:\n",
    "    str_sql=\"create schema sandbox;\"\n",
    "    cur.execute(str_sql)\n",
    "    conn.commit()\n",
    "str_sql='select schema_name FROM information_schema.schemata;'\n",
    "cur.execute(str_sql)\n",
    "conn.commit()\n",
    "print(cur.fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created or have confirmed the existance of the sandbox schema, we should be able to use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[('George',), ('Jane',), ('Judy',), ('Elroy',), ('Astro',), ('Rosie',)]\n"
     ]
    }
   ],
   "source": [
    "str_sql = \"SELECT exists(select * FROM information_schema.tables WHERE table_schema = 'sandbox' and table_name = 'test');\"\n",
    "cur.execute(str_sql)\n",
    "conn.commit()\n",
    "table_exists =cur.fetchone()[0]\n",
    "print(table_exists)\n",
    "str_sql_drop = \"drop table sandbox.test;\"\n",
    "if table_exists==True:\n",
    "    cur.execute(str_sql_drop)\n",
    "\n",
    "str_sql = \"create table sandbox.test(name varchar(100), primary key(name));\"\n",
    "cur.execute(str_sql)\n",
    "str_sql = \"insert into sandbox.test(name) values('George');\"\n",
    "cur.execute(str_sql)\n",
    "str_sql = \"insert into sandbox.test(name) values('Jane');\"\n",
    "cur.execute(str_sql)\n",
    "str_sql = \"insert into sandbox.test(name) values('Judy');\"\n",
    "cur.execute(str_sql)\n",
    "str_sql = \"insert into sandbox.test(name) values('Elroy');\"\n",
    "cur.execute(str_sql)\n",
    "str_sql = \"insert into sandbox.test(name) values('Astro');\"\n",
    "cur.execute(str_sql)\n",
    "str_sql = \"insert into sandbox.test(name) values('Rosie');\"\n",
    "cur.execute(str_sql)\n",
    "conn.commit()\n",
    "\n",
    "str_sql = \"select * from sandbox.test;\"\n",
    "cur.execute(str_sql)\n",
    "conn.commit()\n",
    "print(cur.fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've tested our connection string and can add tables to the sandbox schema, we can detlete the test table then pull in the MERRA2 data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(str_sql_drop)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are cases where the file might be larger than the computer memory running this notebook. We will get just the first few rows to determine the file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat       float64\n",
      "lon       float64\n",
      "time       object\n",
      "H1000     float64\n",
      "H850      float64\n",
      "PBLTOP    float64\n",
      "PS        float64\n",
      "SLP       float64\n",
      "T10M      float64\n",
      "T2M       float64\n",
      "T2MDEW    float64\n",
      "T850      float64\n",
      "TS        float64\n",
      "U10M      float64\n",
      "U2M       float64\n",
      "U50M      float64\n",
      "V10M      float64\n",
      "V2M       float64\n",
      "V50M      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "fname='raw_data_lhbvlh_2014_2015.csv'\n",
    "if os.path.isfile(fname):\n",
    "    data = pd.read_csv(fname, nrows=50)\n",
    "else:\n",
    "    raise SystemExit(\"Stop right there!\")\n",
    "    \n",
    "x=data.dtypes\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted in the 00 file, the MERRA2 data is fully described in https://gmao.gsfc.nasa.gov/pubs/docs/Bosilovich785.pdf. \n",
    "\n",
    "We can use the dtypes to create a table in our postgres database. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data_lhbvlh_2014_2015.csv\n"
     ]
    }
   ],
   "source": [
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deleted and replaced',\n",
       " 'CREATE TABLE raw_data_lhbvlh_2014_2015 (lat real, lon real, time timestamp, H1000 real, H850 real, PBLTOP real, PS real, SLP real, T10M real, T2M real, T2MDEW real, T850 real, TS real, U10M real, U2M real, U50M real, V10M real, V2M real, V50M real);']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note this is strictly a drop and replace, it will not append data as written\n",
    "def maketable(fname):\n",
    "    type_map={'float64':'real',\n",
    "          'int64':'bigint',\n",
    "          'object':'timestamp'}\n",
    "    newtablename=re.sub('.csv','',fname,flags=re.I)\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM information_schema.tables \"+\n",
    "                \"WHERE table_schema = 'sandbox' AND table_name = '\"+newtablename+\"');\")\n",
    "    if cur.fetchone()[0]:\n",
    "        cur.execute(\"DROP TABLE \"+newtablename+';')\n",
    "        conn.commit()\n",
    "        msg='deleted and replaced'\n",
    "    else:\n",
    "        msg='created new'\n",
    "    data = pd.read_csv(fname,nrows=50)\n",
    "    types=data.dtypes\n",
    "    str_sql='CREATE TABLE sandbox.'+newtablename+' ('\n",
    "    len_x=len(data.columns.tolist())\n",
    "    for x in data.columns.tolist():\n",
    "        str_sql=str_sql+x+' '+  type_map[str(types[x])]\n",
    "        if(x!=data.columns.tolist()[len_x-1]):\n",
    "            str_sql=str_sql + ', '\n",
    "        else :\n",
    "            str_sql=str_sql+ ');'\n",
    "    cur.execute(str_sql)\n",
    "    conn.commit()\n",
    "    return [msg,str_sql]  \n",
    "\n",
    "maketable(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table has been created based on the structure of the data, so no we can import the csv directly into the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedTable",
     "evalue": "relation \"sandbox.raw_data_lhbvlh_2014_2015\" does not exist\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-537959fb8c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtablename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_expert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy sandbox.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtablename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" from STDOUT delimiter ',' csv header\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUndefinedTable\u001b[0m: relation \"sandbox.raw_data_lhbvlh_2014_2015\" does not exist\n"
     ]
    }
   ],
   "source": [
    "tablename=re.sub('.csv','',fname,flags=re.I)\n",
    "f=open(fname)\n",
    "cur.copy_expert(\"copy sandbox.\"+tablename+\" from STDOUT delimiter ',' csv header\",f)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in the database, we can pull what we want into pandas, or continue working with data in teh database and doing data wrangling and munging directly with sql.\n",
    "\n",
    "Here's an example of pullin data into pandas using its ability to read sql.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_sql = \"select * from sandbox.\"+tablename+\" limit 5;\"\n",
    "data=pdsqlio.read_sql_query(str_sql,conn)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
